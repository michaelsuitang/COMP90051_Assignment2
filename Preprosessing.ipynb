{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e7e1a87-5f13-4084-8f38-84f912c1f9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "from typing import Optional, Union\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7475a5cb-b947-4bcd-875e-2c6b06493e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===================training set -> preprocessing + augmentation====================\n",
    "#===================test set -> preprocessing====================\n",
    "\n",
    "# add Gaussian noise\n",
    "class AddGaussianNoise(object):\n",
    "    def __init__(self, mean=0.0, std=0.05, p=0.5):\n",
    "        \"\"\"\n",
    "        mean: Gaussian noise mean\n",
    "        std: Gaussian noise standard deviation\n",
    "        p:   Probability of applying noise\n",
    "        \"\"\"\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        if torch.rand(1).item() < self.p:  # Decide whether to add noise based on probability\n",
    "            noise = torch.randn_like(tensor) * self.std + self.mean\n",
    "            tensor = tensor + noise\n",
    "        return tensor.clamp(0., 1.)  # Clamp to [0,1]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self.__class__.__name__}(mean={self.mean}, std={self.std}, p={self.p})\"\n",
    "\n",
    "\n",
    "# preprocessing + augmentation for training set\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),                         # resize\n",
    "    transforms.RandomHorizontalFlip(p=0.5),                # horizontal flip\n",
    "    transforms.RandomRotation(degrees=15),                 # rotation ±15°\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),  # brightness and contrast adjustment\n",
    "    transforms.ToTensor(),\n",
    "    AddGaussianNoise(mean=0.0, std=0.05, p=0.5),           # add Gaussian noise\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                         std=[0.5, 0.5, 0.5])])\n",
    "\n",
    "# preprocessing for test set\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                         std=[0.5, 0.5, 0.5])])\n",
    "\n",
    "\n",
    "# dataset definition\n",
    "class ImageDataset(Dataset):\n",
    "    \"\"\"\n",
    "    General-purpose and CelebA-friendly image dataset:\n",
    "    - Unified RGB, resize, and normalization\n",
    "    - Supports both supervised/unsupervised learning\n",
    "    - Supports mapping CelebA labels {-1, 1} to {0, 1} (can be disabled/customized)\n",
    "    - labels can be pandas.Series / dict / None\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        image_file_list,\n",
    "        image_dir: str = \"data/img_align_celeba/img_align_celeba\",\n",
    "        labels: Optional[Union[\"pd.Series\", dict]] = None,\n",
    "        transform: Optional[nn.Module] = None,\n",
    "        label_mapping: Optional[dict] = {-1: 0, 1: 1},\n",
    "        return_filename: bool = False,\n",
    "    ):\n",
    "        assert os.path.exists(image_dir), f\"Image dir not found: {image_dir}\"\n",
    "        self.image_dir = image_dir\n",
    "        self.image_files = list(image_file_list)\n",
    "        self.transform = transform\n",
    "        self.labels = labels\n",
    "        self.label_mapping = label_mapping\n",
    "        self.return_filename = return_filename\n",
    "\n",
    "        # Try to detect pandas.Series\n",
    "        self._is_pandas_series = False\n",
    "        try:\n",
    "            import pandas as pd  # Only used for type checking\n",
    "            self._is_pandas_series = isinstance(labels, pd.Series)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def _get_label(self, img_name):\n",
    "        if self.labels is None:\n",
    "            return 0  # unsupervised: placeholder label\n",
    "\n",
    "        # pandas.Series\n",
    "        if self._is_pandas_series:\n",
    "            y = self.labels.loc[img_name]\n",
    "        else:  # dict-like\n",
    "            y = self.labels[img_name]\n",
    "\n",
    "        # Optional mapping (for CelebA: -1/1 -> 0/1)\n",
    "        if self.label_mapping is not None:\n",
    "            y = self.label_mapping.get(int(y), y)\n",
    "        return int(y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files[idx]\n",
    "        img_path = os.path.join(self.image_dir, img_name)\n",
    "\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        label = self._get_label(img_name)\n",
    "\n",
    "        if self.return_filename:\n",
    "            return image, label, img_name\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76551e04-251d-4e6b-8bcc-99a9f93fabff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     image_id  partition\n",
      "0  000001.jpg          0\n",
      "1  000002.jpg          0\n",
      "2  000003.jpg          0\n",
      "3  000004.jpg          0\n",
      "4  000005.jpg          0\n",
      "Train: 162770 Test: 19962\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Use pandas to read a CSV file\n",
    "df = pd.read_csv(r\"C:\\Users\\HOU HENGJIN\\Desktop\\90051\\data\\list_eval_partition.csv\")\n",
    "\n",
    "# check the first few rows\n",
    "print(df.head())\n",
    "\n",
    "# verify the column names: [\"image_id\", \"partition\"]\n",
    "train_files = df.loc[df[\"partition\"] == 0, \"image_id\"].tolist()\n",
    "test_files  = df.loc[df[\"partition\"] == 2, \"image_id\"].tolist()\n",
    "\n",
    "print(\"Train:\", len(train_files), \"Test:\", len(test_files))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c098e3f9-ae2b-4c86-99f8-a9acfef77595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162770 19962\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define the directory of the image dataset\n",
    "IMAGE_DIR = Path(r\"C:\\Users\\HOU HENGJIN\\Desktop\\90051\\data\\img_align_celeba\") \n",
    "\n",
    "# Create the training dataset\n",
    "train_ds = ImageDataset(\n",
    "    image_file_list=train_files,   # list of training image filenames\n",
    "    image_dir=str(IMAGE_DIR),      # directory where the images are stored\n",
    "    labels=None,                   # no labels for now (unsupervised / placeholder)\n",
    "    transform=train_transform      # preprocessing + augmentation for training set\n",
    ")\n",
    "\n",
    "# Create the testing dataset\n",
    "test_ds = ImageDataset(\n",
    "    image_file_list=test_files,    # list of testing image filenames\n",
    "    image_dir=str(IMAGE_DIR),      # directory where the images are stored\n",
    "    labels=None,                   # no labels for now\n",
    "    transform=test_transform       # preprocessing only for test set\n",
    ")\n",
    "\n",
    "# Create DataLoaders to efficiently load data in batches\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=64,     # number of images per batch\n",
    "    shuffle=True,      # shuffle the training data at every epoch\n",
    "    num_workers=4,     # number of subprocesses to use for data loading\n",
    "    pin_memory=True    # speeds up transfer to GPU\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_ds,\n",
    "    batch_size=64,     # number of images per batch\n",
    "    shuffle=False,     # do not shuffle test data\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "# Print dataset sizes\n",
    "print(len(train_ds), len(test_ds))  # Expected output: 162770, 19962"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "199d9cdc-765a-47db-a5f2-870633e86eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Create DataLoader for the training dataset\n",
    "train_loader = DataLoader(\n",
    "    train_ds,           # dataset object for training data\n",
    "    batch_size=64,      # number of samples per batch\n",
    "    shuffle=True,       # shuffle the training data at every epoch\n",
    "    num_workers=0,      # for windows + jupyternotebook, num_workers=0 / for GPU,num_workers can be 4 or 8\n",
    "    pin_memory=torch.cuda.is_available()     # speeds up host-to-GPU memory transfer\n",
    ")\n",
    "\n",
    "# Create DataLoader for the testing dataset\n",
    "test_loader = DataLoader(\n",
    "    test_ds,            # dataset object for testing data\n",
    "    batch_size=64,      # number of samples per batch\n",
    "    shuffle=False,      # keep test data order fixed (no shuffling)\n",
    "    num_workers=0,      # for windows + jupyternotebook, num_workers=0 / for GPU,num_workers can be 4 or 8\n",
    "    pin_memory=torch.cuda.is_available()     # speeds up host-to-GPU memory transfer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9160d91b-3740-4047-9dc4-59b176402de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 224, 224])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "# try one batch\n",
    "images, labels = next(iter(train_loader))\n",
    "print(images.shape)   # torch.Size([64, 3, H, W])\n",
    "print(labels)         # apply attributes in celeA to change labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e678079-47d3-4216-85c7-f20f9b87fdf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
